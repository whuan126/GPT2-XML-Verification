{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 0. HuggingFace"
      ],
      "metadata": {
        "id": "S815a6jc8qL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUalGQS52kcf",
        "outputId": "248faa94-4b1b-443a-9827-5ba9dc0bc83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPli-68G2kci"
      },
      "source": [
        "### 1. Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaqOSd2X2kcj"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBRgbtCW2kcj"
      },
      "source": [
        "### 2. Load pre-trained GPT2 models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVJj4EOf2kck"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id = tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kba5LZHu2kck"
      },
      "source": [
        "### 3. Provide example xml (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dhugiUX2kck"
      },
      "outputs": [],
      "source": [
        "example_xml = \"\"\"\n",
        "    <car>\n",
        "        <make>Honda</make>\n",
        "        <model>Civic</model>\n",
        "        <year>2014</year>\n",
        "    </car>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUfC8KBy2kcl"
      },
      "source": [
        "### 4. Design the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK5CQw6a2kcl"
      },
      "outputs": [],
      "source": [
        "prompt1 = example_xml + \"This is an example xml. Generate a new xml featuring a menu: \\n <Menu>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3UyoTSz2kcl"
      },
      "source": [
        "### 5. Generate the text and XML content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPyz5f5O2kcm"
      },
      "outputs": [],
      "source": [
        "generated_text = model.generate(\n",
        "    tokenizer.encode(prompt1, return_tensors=\"pt\"),\n",
        "    max_length=50,\n",
        "    do_sample = True,\n",
        "    num_beams=1,\n",
        "    no_repeat_ngram_size=5,\n",
        "    top_k = 50,\n",
        "    top_p = 1,\n",
        "    temperature = 1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK7hPnmE2kcm"
      },
      "source": [
        "\n",
        "* input_ids: This is the tensor containing the input sequence.\n",
        "\n",
        "* max_length: The maximum length of the generated sequence.\n",
        "\n",
        "* do_sample: if set to True, the parameter allows decoding strategies such as beam search, top-k, and top-p sampling.\n",
        "\n",
        "* num_beams: Number of steps for beam search. Beam search is a technique used in sequence generation to explore multiple possible sequences concurrently. This can help improve the quality of the generated text.\n",
        "\n",
        "* no_repeat_ngram_size: Size of n-grams that should not be repeated. N-gram is a sequence of N words This helps the model avoid repetitive patterns in generated text.\n",
        "\n",
        "* top_k: How many potential tokens are considered when sampling.\n",
        "\n",
        "* top_p: Cumulative probability threshold for nucleus sampling. This is an alternative to top-k sampling. The difference is it selects the next token based on the smallest set of tokens which the cumulative probability exceeds a specified value. Can also be used concurrently with top_k.\n",
        "\n",
        "* temperature: Used for controlling randomness in sampling. A lower temperature (closer to 0.0) results in less random completions. As the temperature approaches zero, the model becomes more deterministic and repetitive. A higher temperature (closer to 1.0 or above) increases randomness and creativity in the generated text, but it can also lead to less coherent outputs.\n",
        "\n",
        "* pad_token_id: ID of the padding token in vocabulary.\n",
        "\n",
        "Source: https://huggingface.co/docs/transformers/generation_strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4mkKNB52kcm"
      },
      "source": [
        "### 6. Decode the generated text and XML content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELKHz7kA2kcm"
      },
      "outputs": [],
      "source": [
        "generated_xml = tokenizer.decode(generated_text[0], skip_special_tokens = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV-XDbWq2kcm",
        "outputId": "996a99c2-a59d-4c45-a4ec-48055a96e09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    <car>\n",
            "        <make></make>\n",
            "        <model></model>\n",
            "        <year></year>\n",
            "    </car>\n",
            "This is an example xml. Generate a new xml featuring a menu: \n",
            " <Menu>\n",
            "\n",
            "<MenuItem name=\"menu\">\n",
            "\n",
            "<Menu item=\"menuItem\">\n",
            "\n",
            "<Item name=\"menuItem\"> <Item name=\"menuitem\">\n",
            "\n",
            "<item name=\"menuitem\" value=\"menuitem\"> <item name=\"menuItem\" value=\"menuItem\"> </item>\n",
            "\n",
            "</item>\n",
            "\n",
            "<Item item=\"menuitem\n"
          ]
        }
      ],
      "source": [
        "print(generated_xml)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Create more prompts and test"
      ],
      "metadata": {
        "id": "mZsYfSvfCnIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt2 = \"Toyota makes three different kinds of vehicles. Generate an XML to categorize these vehicle types \\n <Toyota>\""
      ],
      "metadata": {
        "id": "nPaOYCo_Gy4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text2 = model.generate(\n",
        "    tokenizer.encode(prompt2, return_tensors=\"pt\"),\n",
        "    max_length=100,\n",
        "    do_sample = True,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=5,\n",
        "    top_k = 50,\n",
        "    top_p = 0.7,\n",
        "    temperature = 1.0,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "VfM64WsNCqi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_xml2 = tokenizer.decode(generated_text2[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "TJ_4u1P9CujL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_xml2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Bjy6C9Cv09",
        "outputId": "b0533b1d-9f17-4084-ddd8-52361457e4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toyota makes three different kinds of vehicles. Generate an XML to categorize these vehicle types \n",
            " <Toyota> <Vehicle> <Name>Toyota</Name> </Vehicle> </Toyota>\n",
            "\n",
            "<Toyota> <vehicle> <name>Toyota</name> </vehicle>\n",
            "\n",
            "<vehicle> <type>Toyota</type>\n",
            "\n",
            "<name>Toyota Prius</name>\n",
            "\n",
            "</vehicle>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt3 = \"There are three primary colors. Generate an XML to summarize these colors \\n <Color>\""
      ],
      "metadata": {
        "id": "Q1zCX_77K7Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text3 = model.generate(\n",
        "    tokenizer.encode(prompt3, return_tensors=\"pt\"),\n",
        "    max_length=100,\n",
        "    do_sample = True,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=5,\n",
        "    top_k = 10,\n",
        "    top_p = 0.7,\n",
        "    temperature = 0.1,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "Y0u896ajKy8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_xml3 = tokenizer.decode(generated_text3[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "FsfUXLX1K0oX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_xml3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gob1XaCSK1YY",
        "outputId": "240e35b5-5bc9-4346-f0b1-4a45d3efbde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are three primary colors. Generate an XML to summarize these colors \n",
            " <Color> <Color name=\"color_1\" color=\"red\" color=\"blue\" color=\"green\" color=\"blue\"> <Color name=\"Color name=\"color2\" color=\"red, green, blue\" color=\"blue, yellow\" color=\"red\"> <Color name=\"\" color=\"red, blue, yellow\" color=\"\" color=\"blue, green, blue\"> <Color name= \"color3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_xml4 = \"\"\"\n",
        "<bookstore>\n",
        "  <book category=\"cooking\">\n",
        "    <title lang=\"en\">Everyday Italian</title>\n",
        "    <author>Giada De Laurentiis</author>\n",
        "    <year>2005</year>\n",
        "    <price>30.00</price>\n",
        "  </book>\n",
        "  <book category=\"children\">\n",
        "    <title lang=\"en\">Harry Potter</title>\n",
        "    <author>J.K. Rowling</author>\n",
        "    <year>2005</year>\n",
        "    <price>29.99</price>\n",
        "  </book>\n",
        "  <book category=\"web\">\n",
        "    <title lang=\"en\">Learning XML</title>\n",
        "    <author>Erik T. Ray</author>\n",
        "    <year>2003</year>\n",
        "    <price>39.95</price>\n",
        "  </book>\n",
        "</bookstore>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RO02NLrZTbG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt4 = example_xml4 + \"This is a XML file showing what genres of books are sold in a bookstore. Generate another one following the same format of category, title, author, year, and price. \\n\""
      ],
      "metadata": {
        "id": "DlYcZuEeRxdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text4 = model.generate(\n",
        "    tokenizer.encode(prompt4, return_tensors=\"pt\"),\n",
        "    max_length=500,\n",
        "    do_sample = True,\n",
        "    num_beams=5,\n",
        "    no_repeat_ngram_size=10,\n",
        "    num_return_sequences=1,\n",
        "    top_k = 50,\n",
        "    top_p = 1,\n",
        "    temperature = 0.3,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "v9to1OifSCQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_xml4 = tokenizer.decode(generated_text4[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "tlMBBJWUSC_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_xml4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYMOsojUSDi3",
        "outputId": "d7f2befe-7970-4033-dc4e-15ab7ec876d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<bookstore>\n",
            "  <book category=\"cooking\">\n",
            "    <title lang=\"en\">Everyday Italian</title>\n",
            "    <author>Giada De Laurentiis</author>\n",
            "    <year>2005</year>\n",
            "    <price>30.00</price>\n",
            "  </book>\n",
            "  <book category=\"children\">\n",
            "    <title lang=\"en\">Harry Potter</title>\n",
            "    <author>J.K. Rowling</author>\n",
            "    <year>2005</year>\n",
            "    <price>29.99</price>\n",
            "  </book>\n",
            "  <book category=\"web\">\n",
            "    <title lang=\"en\">Learning XML</title>\n",
            "    <author>Erik T. Ray</author>\n",
            "    <year>2003</year>\n",
            "    <price>39.95</price>\n",
            "  </book>\n",
            "</bookstore>\n",
            "This is a XML file showing what genres of books are sold in a bookstore. Generate another one following the same format of category, title, author, year, and price. \n",
            "<bookstore>  <book category=\"cooking\">    <title lang=\"en\">Italian</title>\n",
            " <author>Giada de Laurentiis</author>    <year>2004</year>\n",
            " <price>30.00</price>  </book>  <book category=\"children\">\n",
            "<book category=\"children\">\n",
            "<title lang=\"en\">Harry Potter and the Philosopher's Stone</title>\n",
            " <author>J. K. Rowling</author>\n",
            " <year>2005</year>\n",
            "\n",
            "<price>29.99</price>  </book>\n",
            "</bookstore>  <book category=\"web\">\n",
            "<book category=\"cooking\">\n",
            "<title lang=\"en\">Japanese</title>\n",
            "\n",
            "<title lang=\"en\">Japanese novels</title>\n",
            "\n",
            "<author>J.K. Rowling</author}\n",
            "\n",
            "<year>2005</year> <price>29.99</price> </book>\n",
            "</bookstore>\n",
            "<book category=\"web\">\n",
            "\n",
            "<book category=\"cooking\">\n",
            "\n",
            "<title lang=\"en\">Japanese manga</title>\n",
            "\n",
            "<title lang=\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt5 = \"Generate a XML file showing a book's genre, language, author, and price \\n <bookstore>\""
      ],
      "metadata": {
        "id": "8i1qjKwAnMnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text5 = model.generate(\n",
        "    tokenizer.encode(prompt5, return_tensors=\"pt\"),\n",
        "    max_length=75,\n",
        "    do_sample = True,\n",
        "    num_beams=1,\n",
        "    no_repeat_ngram_size=5,\n",
        "    top_k = 50,\n",
        "    top_p = 1,\n",
        "    temperature = 0.8,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "dzMeQBfSnFO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_xml5 = tokenizer.decode(generated_text5[0], skip_special_tokens = True)"
      ],
      "metadata": {
        "id": "JHFhY22GnyO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_xml5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-evRYLFnzpj",
        "outputId": "f32daa49-2923-4018-f2e0-a7c470a049ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate a XML file showing a book's genre, language, author, and price \n",
            " <bookstore> <title>HarperCollins.com - The Bookseller of the Century (2005)</title> </bookstore> <author>HarperCollins</author> <prices> <pricescene> <author>Charles Scribner</author>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}